{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb1a0d8-6433-4f65-9033-ae48ca538233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Načtení datasetu\n",
    "dataset = load_dataset(\"Diplomkaazvposlednimsemestru/MUNIAI\")\n",
    "train_data = dataset['train'][200:300]['text']  # Data pro trénink\n",
    "test_data = dataset['train'][350:420]['text']   # Data pro testování"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5085a41-d7d5-4f49-b12f-272714ed308b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.5.1\n",
      "Uninstalling torch-2.5.1:\n",
      "  Successfully uninstalled torch-2.5.1\n",
      "Found existing installation: torchvision 0.20.1\n",
      "Uninstalling torchvision-0.20.1:\n",
      "  Successfully uninstalled torchvision-0.20.1\n",
      "Found existing installation: torchaudio 2.5.1\n",
      "Uninstalling torchaudio-2.5.1:\n",
      "  Successfully uninstalled torchaudio-2.5.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://download.pytorch.org/whl/cpu/torch_stable.html\n",
      "Collecting torch==2.0.1+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.0.1%2Bcpu-cp310-cp310-linux_x86_64.whl (195.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 MB\u001b[0m \u001b[31m256.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.0.1+cpu) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.0.1+cpu) (4.12.2)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.0.1+cpu) (1.13.1)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.0.1+cpu) (3.3)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.0.1+cpu) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch==2.0.1+cpu) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch==2.0.1+cpu) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: torch\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lightning 2.4.0 requires torch<4.0,>=2.1.0, but you have torch 2.0.1+cpu which is incompatible.\n",
      "pytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 2.0.1+cpu which is incompatible.\n",
      "unsloth 2024.11.5 requires torch>=2.4.0, but you have torch 2.0.1+cpu which is incompatible.\n",
      "xformers 0.0.28.post3 requires torch==2.5.1, but you have torch 2.0.1+cpu which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.0.1+cpu\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch torchvision torchaudio\n",
    "!pip install torch==2.0.1+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66728168-03f6-45ae-a50f-380c31ba1a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # Zkontrolujte verzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19dd010-c243-4097-8df1-7fd0c59c4b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "token = \"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\"  # Vložte svůj token zde\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d03e249a-2cdf-4c19-b046-dd9947192936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f28b22c1fcb477f8bee32353aea7cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/33.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aec83379d4c4eb2bf039a753146b51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a19d61499ba43f89fc3293eee70d646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be955645ac0d4fcf926d6091d5a9b708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f683bd561ee4650af72d8823a583ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ede960cc4646ea884ce54b59ae2ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0dbad9e7d334c58a806143e8c0d3089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc039968ba684a21a79555416da49aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3bea652d424162921938cbd2434e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735f8a722a964fbe9d9af1c8af7f4670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e303ccae004fff808e28e43b328cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toto je příklad textu pro testování modelu.\n",
      "\n",
      "Toto je příklad textu pro testování modelu.\n",
      "\n",
      "Toto je příklad textu pro testování modelu.\n",
      "\n",
      "Toto je příklad textu pro testování modelu.\n",
      "\n",
      "Toto je příklad textu\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Název modelu na Hugging Face Hub\n",
    "model_name = \"google/gemma-2b\"\n",
    "\n",
    "# Načtení tokenizeru a modelu\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Testování na nějakém textu\n",
    "test_text = \"Toto je příklad textu pro testování modelu.\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs[\"input_ids\"], max_length=50)\n",
    "\n",
    "# Dekódování výstupu zpět na text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9612d031-cff7-4795-a527-e3b75a95002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Načtení tokenizeru pro gemma-2b model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6388453b-f288-49cf-a53e-5e7dcb207cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54a6514584b46cfb870600bab28d518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "# Load configuration with a custom activation function if desired\n",
    "config = AutoConfig.from_pretrained(\"google/gemma-2b\")\n",
    "config.hidden_activation = \"gelu\"  # Change to any supported activation function\n",
    "\n",
    "# Load the model with the modified config\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48167598-a9e0-4af1-b956-c52478d44e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 26:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.271111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.556897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.591957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=39, training_loss=4.259962424253806, metrics={'train_runtime': 1621.3719, 'train_samples_per_second': 0.185, 'train_steps_per_second': 0.024, 'total_flos': 531541400371200.0, 'train_loss': 4.259962424253806, 'epoch': 3.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "max_length = 512  # Nastavte maximální délku podle potřeby\n",
    "\n",
    "# Tokenizace trénovacích a testovacích dat\n",
    "train_encodings = tokenizer(train_data, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
    "test_encodings = tokenizer(test_data, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
    "\n",
    "# Přidáme 'labels' ke každému datasetu (pro auto-regresivní trénink modelu)\n",
    "train_encodings['labels'] = train_encodings['input_ids']\n",
    "test_encodings['labels'] = test_encodings['input_ids']\n",
    "\n",
    "# Převedeme tokenizovaná data na Dataset formát\n",
    "train_dataset = Dataset.from_dict(train_encodings)\n",
    "test_dataset = Dataset.from_dict(test_encodings)\n",
    "\n",
    "# Definujeme trénovací argumenty\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # Uložení výsledků\n",
    "    evaluation_strategy=\"epoch\",  # Testování po každé epoše\n",
    "    learning_rate=2e-5,  # Nastavení rychlosti učení\n",
    "    per_device_train_batch_size=8,  # Velikost dávky pro trénování\n",
    "    per_device_eval_batch_size=8,  # Velikost dávky pro testování\n",
    "    num_train_epochs=3,  # Počet epoch\n",
    "    weight_decay=0.01,  # Regularizace\n",
    ")\n",
    "\n",
    "# Definování trenéra\n",
    "trainer = Trainer(\n",
    "    model=model,  # Model\n",
    "    args=training_args,  # Argumenty pro trénování\n",
    "    train_dataset=train_dataset,  # Trénovací data ve formátu Dataset\n",
    "    eval_dataset=test_dataset,  # Testovací data ve formátu Dataset\n",
    ")\n",
    "\n",
    "# Trénování modelu\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e7f99e-c2f0-403e-9785-1908cbdb0f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbf764994604dfcaf2c0881d3ea170a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8a74360b1d4bf3aa55e5b67abd190c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93c492e650146378c90807b03f9ce35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0827f19ca44fda845fd99b1b36acae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4047ecd771a144caa6ccc88990377019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7ecc84a33446d7b9de43e5ca4c1fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11c654ce0a34050b0df2c9c23d01fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c53504efb18497faefed71c2515cf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Diplomkaazvposlednimsemestru/gemma-2-2b-alternative/commit/05996cf87d114cc5ba494aca77d3d0d64b77cd27', commit_message='Upload tokenizer', commit_description='', oid='05996cf87d114cc5ba494aca77d3d0d64b77cd27', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Diplomkaazvposlednimsemestru/gemma-2-2b-alternative', endpoint='https://huggingface.co', repo_type='model', repo_id='Diplomkaazvposlednimsemestru/gemma-2-2b-alternative'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Přihlášení na Hugging Face (pokud ještě nejste přihlášeni)\n",
    "login(token=\"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\")\n",
    "\n",
    "# Uložení modelu na Hub\n",
    "model.push_to_hub(\"gemma-2-2b-alternative\")  # Zadejte název modelu na Hub\n",
    "tokenizer.push_to_hub(\"gemma-2-2b-alternative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19387acb-135a-4b6c-9aaf-9ab0ff435408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67efd4debd264a38b059c7a4106d8afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/40.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b786ce884c4738b67a2cf5862b0309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbefb8e13091454c85a3db051fe7d646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffcccc64e2c4ec5b02f0ecbde580d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9509dcfb5fe6467d88df8d2fbd31cd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0185ddca71a3446cb0e809d282ba80aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ba35de0b4f44a9bd13052de1d67306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0274db1857481189e34a82a48a7c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a105b151e4464efcba7135e6198c3d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ccae6f699d4682aa1579238a5b6a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081c7778644c46b1863182245daf15b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c93fd1f08094353986add6067374ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vygenerovaný text:\n",
      "V roce 2050 dosáhla umělá inteligence úrovně, která překonala lidské schopnosti. Lidé se začali ptát, co bude s jejich pracovními místy a jaká budoucnost je čeká, pokud stroje převezmou kontrolu nad... světem. V roce -2155 se objevuje první počítač, který je schopen komunikovat s lidmi. Počítač se jmenuje HAL 9\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Načtení modelu a tokenizeru z Hugging Face Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Diplomkaazvposlednimsemestru/gemma-2-2b-alternative\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Diplomkaazvposlednimsemestru/gemma-2-2b-alternative\")\n",
    "\n",
    "# Testovací text, který chcete předložit modelu pro generování\n",
    "test_text = \"V roce 2050 dosáhla umělá inteligence úrovně, která překonala lidské schopnosti. Lidé se začali ptát, co bude s jejich pracovními místy a jaká budoucnost je čeká, pokud stroje převezmou kontrolu nad...\"\n",
    "\n",
    "# Tokenizace vstupního textu\n",
    "input_ids = tokenizer(test_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Generování textu\n",
    "generated_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_length=100,         # Nastavení maximální délky generovaného textu\n",
    "    num_return_sequences=1, # Počet návratových sekvencí\n",
    "    no_repeat_ngram_size=2, # Vyhýbá se opakování stejné sekvence\n",
    "    temperature=0.7,        # Kontrola náhodnosti generování (čím nižší, tím předvídatelnější)\n",
    "    top_p=0.9,              # Vybírá tokeny na základě kumulativní pravděpodobnosti\n",
    ")\n",
    "\n",
    "# Dekódování generovaného textu\n",
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Výpis výsledku\n",
    "print(\"Vygenerovaný text:\")\n",
    "print(generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
